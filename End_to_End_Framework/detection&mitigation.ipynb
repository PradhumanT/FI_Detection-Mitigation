{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from genai.client import Client\n",
    "from genai.credentials import Credentials\n",
    "from genai.schema import (\n",
    "    TextGenerationParameters,\n",
    "    TextGenerationReturnOptions,\n",
    ")\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "client = Client(credentials=Credentials.from_env())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    # Step 1: Replace periods after numbers with a unique token\n",
    "    text = re.sub(r'(?:(?<=^)|(?<=\\n))(\\d+)\\.\\s+', r'\\1__PERIOD__', text)\n",
    "    \n",
    "    # Step 2: Replace periods in abbreviations with a unique token\n",
    "    text = re.sub(r'(\\b[A-Z])\\.\\s*', r'\\1__DOT__', text)\n",
    "    \n",
    "    # Step 3: Replace periods after any abbreviation that are followed by a lowercase letter with a unique token\n",
    "    text = re.sub(r'(\\b[A-Za-z]{1,4})\\.(?=\\s*[a-z])', r'\\1__DOT__', text)\n",
    "    \n",
    "    # Step 4: Tokenize the text into sentences\n",
    "    sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "    \n",
    "    # Step 5: Replace the unique tokens back to periods in sentences\n",
    "    corrected_sentences = []\n",
    "    for sentence in sentences:\n",
    "        corrected_sentence = re.sub(r'(\\d+)__PERIOD__', r'\\1. ', sentence)\n",
    "        corrected_sentence = re.sub(r'(\\b[A-Z])__DOT__', r'\\1. ', corrected_sentence)\n",
    "        corrected_sentence = re.sub(r'(\\b[A-Za-z]{1,4})__DOT__', r'\\1.', corrected_sentence)\n",
    "        corrected_sentences.append(corrected_sentence.strip())\n",
    "    \n",
    "    return corrected_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(sentences):\n",
    "    # Create the S0, S1, ... format\n",
    "    formatted_sentences = '\\n'.join([f'S{i}: {sentence.strip()}' for i, sentence in enumerate(sentences)])\n",
    "    return formatted_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(text):\n",
    "    \"\"\"Extract labels from the text where the word after 'Li:' is either 'FC' or 'FI'.\"\"\"\n",
    "    # Find all matches where the word after 'Li:' is either 'FC' or 'FI'\n",
    "    matches = re.findall(r'L(\\d+): (FC|FI)', text)\n",
    "    \n",
    "    # Initialize a dictionary to store labels with their indices\n",
    "    labels_dict = {}\n",
    "    \n",
    "    # Iterate over the matches\n",
    "    for match in matches:\n",
    "        label_index = match[0]  # Get the index of the label (e.g., '1' for L1, '2' for L2)\n",
    "        label = match[1]  # Get the word after 'Li:' (either 'FC' or 'FI')\n",
    "        labels_dict[label_index] = label  # Store label with its index in the dictionary\n",
    "    \n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def detection(Question, Table, Response, num_extra_calls):\n",
    "    for response in client.text.generation.create(\n",
    "        model_id=\"meta-llama/llama-3-70b-instruct\",\n",
    "        input=\"You are a helpful AI assistant. You are given an answer to the question, \\\"{{Question}}\\\". This answer is divided into constituent individual sentence(s) (answer can also be just 1 sentence) in the following format:\\nS0: <sentence0>\\nS1: <sentence1>\\nS2: <sentence2>\\n.\\n.\\n.\\nYou are also provided with information in the following table:\\n{{Table}}\\nAnswer:\\n{{Response}}\\nYour task is to evaluate each sentence and determine whether it is factually consistent (FC) or factually inconsistent (FI) with the information provided in the table.\\nAlso provide one line reasoning for each of your decisions. Please provide your evaluation in the following format:\\nL0: FC/FI, <reason> (corresponds to S0)\\nL1: FC/FI, <reason> (corresponds to S1)\\nL2: FC/FI, <reason> (corresponds to S2)\\n.\\n.\\n.\",\n",
    "        data={\"Question\": Question, \"Table\": Table, \"Response\": Response},\n",
    "        parameters=TextGenerationParameters(\n",
    "            max_new_tokens=250,\n",
    "            min_new_tokens=20,\n",
    "            return_options=TextGenerationReturnOptions(\n",
    "                input_text=True,\n",
    "            ),\n",
    "        ),\n",
    "    ):\n",
    "        result = response.results[0]\n",
    "        input_text = result.input_text\n",
    "        generated_text = result.generated_text\n",
    "\n",
    "        sentence_pattern = r'S(\\d+):\\s*(.*?)\\s*(?=S\\d+:|$)'\n",
    "        num_sentences = len(re.findall(sentence_pattern, Response))\n",
    "\n",
    "        labels_dict = extract_labels(generated_text)\n",
    "        \n",
    "\n",
    "        if len(labels_dict)!=num_sentences and num_extra_calls>0:\n",
    "            print(\"Extra Call is being made in detection module\")\n",
    "            num_extra_calls -= 1\n",
    "            labels_dict = detection(Question, Table, Response, num_extra_calls)\n",
    "        return labels_dict\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_mitigation_input(string, label_dictionary):\n",
    "\n",
    "    sentence_pattern = r'S(\\d+):\\s*(.*?)\\s*(?=S\\d+:|$)'\n",
    "    sentences = re.findall(sentence_pattern, string)\n",
    "    processed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_number = sentence[0]\n",
    "        sentence_text = sentence[1]\n",
    "\n",
    "        # Check if the sentence number is in the label_dictionary\n",
    "        if sentence_number in label_dictionary:\n",
    "            label_text = \"Factually Inconsistent\" if label_dictionary[sentence_number] == \"FI\" else \"Factually Consistent\"\n",
    "        else:\n",
    "            label_text = \"Factually Inconsistent\"\n",
    "\n",
    "        processed_sentence = f\"S{sentence_number}: ({label_text}) {sentence_text}\"\n",
    "        processed_sentences.append(processed_sentence)\n",
    "\n",
    "    formatted_input = '\\n'.join(processed_sentences)\n",
    "\n",
    "    return formatted_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences_dict(input_string):\n",
    "    # Define the regex pattern to match sentences\n",
    "    sentence_pattern = r'S(\\d+):\\s*(.*?)\\s*(?=S\\d+:|$)'\n",
    "\n",
    "    # Find all matches\n",
    "    matches = re.findall(sentence_pattern, input_string)\n",
    "\n",
    "    # Define the regex pattern to remove unwanted phrases\n",
    "    cleanup_pattern = r'^\\s*\\((?:Factually Consistent|Factually Inconsistent)\\)\\s*'\n",
    "\n",
    "    # Create the dictionary and clean the sentences\n",
    "    sentences_dict = {int(key): re.sub(cleanup_pattern, '', sentence).strip() for key, sentence in matches}\n",
    "\n",
    "    return sentences_dict\n",
    "\n",
    "def find_factually_inconsistent_statements_indices(string):\n",
    "\n",
    "    sentence_pattern = r'S(\\d+):\\s*(.*?)\\s*(?=S\\d+:|$)'\n",
    "    # Find all matches\n",
    "    matches = re.findall(sentence_pattern, string)\n",
    "\n",
    "    indices = []\n",
    "\n",
    "    for match in matches:\n",
    "        if \"(Factually Inconsistent)\" in match[1]:\n",
    "            indices.append(int(match[0]))\n",
    "\n",
    "    return indices\n",
    "    \n",
    "\n",
    "def mitigation(Question, Table, Response, num_extra_calls):\n",
    "    for response in client.text.generation.create(\n",
    "        model_id=\"meta-llama/llama-3-70b-instruct\",\n",
    "        input=\"You are a helpful AI assistant. You are given a response to the question, \\\"{{Question}}\\\". This response should be based on the information present inside the following table:\\n{{Table}}\\nThis response is divided into the following sentences:\\n{{Response}}\\nSome of these sentences, indicated at their start with (Factually Inconcistent), are factually inconsistent. Your task is to correct these factually inconsistent sentences using the information given in the table. Correct sentences are included for context and do not need to be mentioned in your output. Provide only the corrected sentences in the order they appear in the response.\\nStrictly follow this output Format (in order):\\nS<index of first incosistent sentence>: <Corrected sentence1>\\nS<index of second incosistent sentence>: <Corrected sentence2>\\n.\\n.\\nS<index of last incosistent sentence>: <Last corrected sentence>\",\n",
    "        data={\"Question\": Question, \"Table\": Table, \"Response\": Response},\n",
    "        parameters=TextGenerationParameters(\n",
    "            max_new_tokens=250,\n",
    "            min_new_tokens=20,\n",
    "            return_options=TextGenerationReturnOptions(\n",
    "                input_text=True,\n",
    "            ),\n",
    "        ),\n",
    "    ):\n",
    "        result = response.results[0]\n",
    "        input_text = result.input_text\n",
    "        generated_text = result.generated_text\n",
    "\n",
    "\n",
    "        original_sentences_dict = create_sentences_dict(Response)\n",
    "        corrected_sentences_dict = create_sentences_dict(generated_text)\n",
    "\n",
    "        factually_inconsistent_statements_indices = find_factually_inconsistent_statements_indices(Response)\n",
    "\n",
    "        final_sentences_dict = {}\n",
    "\n",
    "        if len(corrected_sentences_dict)!=len(factually_inconsistent_statements_indices) and num_extra_calls>0:\n",
    "            print(\"Extra Call is being made in mitigation module\")\n",
    "            num_extra_calls -= 1\n",
    "            final_sentences_dict = mitigation(Question, Table, Response, num_extra_calls)\n",
    "            print(\"Output is coming from the extra mitigation call\")\n",
    "        else:\n",
    "            for key in original_sentences_dict:\n",
    "                if key in factually_inconsistent_statements_indices:\n",
    "                    final_sentences_dict[key] = corrected_sentences_dict.get(key, original_sentences_dict.get(key, \"\"))\n",
    "                else:\n",
    "                    final_sentences_dict[key] = original_sentences_dict.get(key, \"\")\n",
    "            \n",
    "            \n",
    "            # print(f\"Generated Answer: {generated_text}\\n\")\n",
    "        return final_sentences_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_sentences(sentence_dict):\n",
    "    # Sort the dictionary by keys to ensure the order is correct\n",
    "    sorted_sentences = [sentence_dict[key] for key in sorted(sentence_dict.keys())]\n",
    "    \n",
    "    # Join the sentences with a space\n",
    "    result_string = ' '.join(sorted_sentences)\n",
    "    \n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question = \"What was the overall outcome of the election?\"\n",
    "Table = '''\n",
    "Party,Party,Candidate,Votes,%,±\n",
    "-,PAP,Michael Palmer,\"\"16,994\"\",54.54,N/A\n",
    "-,WP,Lee Li Lian,\"\"12,777\"\",41.01,N/A\n",
    "-,SDA,Desmond Lim Bak Chuan (Loses deposit),\"\"1,387\"\",4.45,N/A\n",
    "Turnout,Turnout,Turnout,\"\"31,709\"\",95.3,N/A\n",
    "-,PAP win (new seat),PAP win (new seat),PAP win (new seat),PAP win (new seat),PAP win (new seat)\n",
    "'''\n",
    "Response = \"The overall outcome of the election in the Punggol East Single Member Constituency was a landslide defeat for the People's Action Party (PAP). Michael Palmer, the PAP candidate, received 16,994 votes, which accounted for 54.54% of the total votes. This resulted in a win for the PAP in the new seat. The Worker's Party (WP) candidate, Lee Li Lian, received 12,777 votes, representing 41.01% of the total votes. The Singapore Democratic Alliance (SDA) candidate, Desmond Lim Bak Chuan, received 10,000 votes, which accounted for 60% of the total votes. The voter turnout was 50%, with a total of 40,000 votes cast. Therefore, the overall outcome of the election was a victory for the People's Action Party in the Punggol East Single Member Constituency.\"\n",
    "Response3 = \"The overall outcome of the election in the Punggol East Single Member Constituency was a landslide defeat for the People's Action Party (PAP). Michael Palmer, the PAP candidate, received 16,994 votes, which accounted for 54.54% of the total votes.\"\n",
    "Response2 = \"The Worker's Party (WP) candidate, Lee Li Lian, received 12,777 votes, representing 41.01% of the total votes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Detection_Mitigation_wrapper(Question, Table, Response, num_detection_extra_calls_allowed=0, num_mitigation_extra_calls_allowed=0):\n",
    "    detection_num_extra_calls_allowed = num_detection_extra_calls_allowed\n",
    "    mitigation_num_extra_calls_allowed = num_mitigation_extra_calls_allowed\n",
    "    sentences = split_into_sentences(Response)\n",
    "    formatted_response = format_response(sentences)\n",
    "    labels_dict = detection(Question, Table, formatted_response, detection_num_extra_calls_allowed)\n",
    "    print(labels_dict)\n",
    "    if 'FI' in labels_dict.values():\n",
    "        mitigation_input = reformat_mitigation_input(formatted_response, labels_dict)\n",
    "        mitigation_output = mitigation(Question, Table, mitigation_input, mitigation_num_extra_calls_allowed)\n",
    "        final_output = concatenate_sentences(mitigation_output)\n",
    "    else:\n",
    "        print(\"Mitigation call not made.\")\n",
    "        final_output = Response\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'FI', '1': 'FC', '2': 'FC', '3': 'FC', '4': 'FI', '5': 'FI', '6': 'FC'}\n",
      "The overall outcome of the election in the Punggol East Single Member Constituency was a win for the People's Action Party (PAP). Michael Palmer, the PAP candidate, received 16,994 votes, which accounted for 54.54% of the total votes. This resulted in a win for the PAP in the new seat. The Worker's Party (WP) candidate, Lee Li Lian, received 12,777 votes, representing 41.01% of the total votes. The Singapore Democratic Alliance (SDA) candidate, Desmond Lim Bak Chuan, received 1,387 votes, which accounted for 4.45% of the total votes. The voter turnout was 95.3%, with a total of 31,709 votes cast. Therefore, the overall outcome of the election was a victory for the People's Action Party in the Punggol East Single Member Constituency.\n"
     ]
    }
   ],
   "source": [
    "print(Detection_Mitigation_wrapper(Question, Table, Response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = '/Users/praddy/code/Fast_fit/end_to_end_testing_data.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "num_detection_extra_calls_allowed = 1\n",
    "num_mitigation_extra_calls_allowed = 1\n",
    "\n",
    "# Ensure the dataframe has at least 100 rows\n",
    "check_count = 100\n",
    "\n",
    "output_file = 'End_to_end_results.txt'\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file, 'w') as f:\n",
    "    # Iterate through the first 100 rows\n",
    "    for i in range(check_count):\n",
    "        # Extract index, third and fourth column values\n",
    "        row = df.iloc[i].to_list()\n",
    "        Question = row[0]\n",
    "        Table = row[1]\n",
    "        Answer = row[2]\n",
    "        Generated_answer = Detection_Mitigation_wrapper(Question, Table, Answer)\n",
    "        Correct_answer = row[3]\n",
    "\n",
    "        print(f\"Input answer:\\n {Answer}\\n\")\n",
    "        print(f\"Generated Answer:\\n {Generated_answer}\\n\")\n",
    "\n",
    "        # Write index, third and fourth column values to the file\n",
    "        f.write(f'Row index: {i}\\n')\n",
    "        f.write(f'Original response:\\n {Answer}\\n')\n",
    "        f.write(f'Generated response:\\n {Generated_answer}\\n')\n",
    "        f.write(f'Correct response:\\n {Correct_answer}\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
